Training/evaluation parameters Namespace(output_dir='./saved_models', model_type='t5', encoder_block_size=512, decoder_block_size=256, beam_size=50, model_name='model.bin', checkpoint_model_name='non_domain_model.bin', model_name_or_path='../codebert-base', config_name='', use_non_pretrained_model=False, tokenizer_name='../codebert-base', code_length=256, do_train=False, do_eval=False, do_test=True, load_model_from_checkpoint=False, evaluate_during_training=False, do_local_explanation=False, reasoning_method=None, train_batch_size=4, eval_batch_size=1, gradient_accumulation_steps=1, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, max_steps=-1, warmup_steps=0, seed=42, epochs=1, n_gpu=1, device=device(type='cuda', index=0))
***** Debugging Inference on Small Sample *****
